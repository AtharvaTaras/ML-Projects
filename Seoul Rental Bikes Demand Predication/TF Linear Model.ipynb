{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d3d080a",
   "metadata": {},
   "source": [
    "# Tensorflow Neural Network\n",
    "\n",
    "- R Squared Score 0.4994\n",
    "\n",
    "Best params\n",
    "\n",
    "model = tf.keras.Sequential([  \n",
    "    tmp_normalizer,  \n",
    "    tf.keras.layers.Dense(64, activation='relu'),  \n",
    "    tf.keras.layers.Dense(32, activation='relu'),  \n",
    "    tf.keras.layers.Dense(32, activation='relu'),  \n",
    "    tf.keras.layers.Dense(16, activation='relu'),  \n",
    "    tf.keras.layers.Dense(1)  \n",
    "])  \n",
    "\n",
    "model.compile(  \n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error'  \n",
    ")  \n",
    "\n",
    "epochs = 500  \n",
    "split size = 0.2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad1e0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840806e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Dew_temp</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>-17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rented Bike Count  Temp  Humidity  Dew_temp  Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm)\n",
       "0                254  -5.2        37     -17.6                      0.0           0.0            0.0\n",
       "1                204  -5.5        38     -17.6                      0.0           0.0            0.0\n",
       "2                173  -6.0        39     -17.7                      0.0           0.0            0.0\n",
       "3                107  -6.2        40     -17.6                      0.0           0.0            0.0\n",
       "4                 78  -6.0        36     -18.6                      0.0           0.0            0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Seoul Bikes Clean')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fceb3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Rented Bike Count', axis=1)\n",
    "y = data['Rented Bike Count'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "212628a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8760, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a971fca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8760, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2af62a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f2b6f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_normalizer = tf.keras.layers.Normalization(input_shape=(6,), axis=None)\n",
    "tmp_normalizer.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9605d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tmp_normalizer,\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0b91b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e787f43",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "219/219 [==============================] - 0s 948us/step - loss: 688235.6875 - val_loss: 417926.0312\n",
      "Epoch 2/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 329868.8438 - val_loss: 287426.6875\n",
      "Epoch 3/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 257293.8438 - val_loss: 261160.1875\n",
      "Epoch 4/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 250585.2344 - val_loss: 257846.2031\n",
      "Epoch 5/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 247342.6406 - val_loss: 255360.9375\n",
      "Epoch 6/500\n",
      "219/219 [==============================] - 0s 674us/step - loss: 244176.3125 - val_loss: 259559.0312\n",
      "Epoch 7/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 241139.2031 - val_loss: 248979.0938\n",
      "Epoch 8/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 238603.0000 - val_loss: 248155.7812\n",
      "Epoch 9/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 237745.6250 - val_loss: 244966.0312\n",
      "Epoch 10/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 237463.6875 - val_loss: 245378.1406\n",
      "Epoch 11/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 235872.9531 - val_loss: 244038.0781\n",
      "Epoch 12/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 235073.2344 - val_loss: 243323.1719\n",
      "Epoch 13/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 235433.5938 - val_loss: 243151.9844\n",
      "Epoch 14/500\n",
      "219/219 [==============================] - 0s 702us/step - loss: 234279.7188 - val_loss: 242577.7344\n",
      "Epoch 15/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 233940.0000 - val_loss: 246351.6094\n",
      "Epoch 16/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 233221.8281 - val_loss: 244041.5781\n",
      "Epoch 17/500\n",
      "219/219 [==============================] - 0s 679us/step - loss: 232805.8281 - val_loss: 240817.7344\n",
      "Epoch 18/500\n",
      "219/219 [==============================] - 0s 674us/step - loss: 232950.9219 - val_loss: 242125.3125\n",
      "Epoch 19/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 231902.0938 - val_loss: 245824.4219\n",
      "Epoch 20/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 231613.5781 - val_loss: 240224.4062\n",
      "Epoch 21/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 231317.2188 - val_loss: 239933.4219\n",
      "Epoch 22/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 230753.9844 - val_loss: 239560.9844\n",
      "Epoch 23/500\n",
      "219/219 [==============================] - 0s 684us/step - loss: 229888.5625 - val_loss: 242734.1562\n",
      "Epoch 24/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 229897.7188 - val_loss: 243374.5938\n",
      "Epoch 25/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 229398.5938 - val_loss: 238881.7969\n",
      "Epoch 26/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 229560.0000 - val_loss: 241174.6094\n",
      "Epoch 27/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 228690.7188 - val_loss: 240290.9219\n",
      "Epoch 28/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 228325.0469 - val_loss: 237750.6094\n",
      "Epoch 29/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 227889.9531 - val_loss: 247038.5625\n",
      "Epoch 30/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 227700.9688 - val_loss: 238780.5469\n",
      "Epoch 31/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 227171.7500 - val_loss: 245363.6719\n",
      "Epoch 32/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 226932.2344 - val_loss: 235793.7500\n",
      "Epoch 33/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 226833.2812 - val_loss: 235788.5469\n",
      "Epoch 34/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 226498.7188 - val_loss: 236469.2031\n",
      "Epoch 35/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 225680.6250 - val_loss: 235461.9375\n",
      "Epoch 36/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 225290.0781 - val_loss: 234928.0312\n",
      "Epoch 37/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 225457.8750 - val_loss: 238925.3906\n",
      "Epoch 38/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 225339.6719 - val_loss: 236444.7812\n",
      "Epoch 39/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 224886.3594 - val_loss: 240172.5781\n",
      "Epoch 40/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 223811.2812 - val_loss: 234002.5312\n",
      "Epoch 41/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 224423.0312 - val_loss: 239704.6875\n",
      "Epoch 42/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 223500.7188 - val_loss: 235981.1719\n",
      "Epoch 43/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 224084.1094 - val_loss: 234103.0469\n",
      "Epoch 44/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 222440.6719 - val_loss: 233839.0000\n",
      "Epoch 45/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 222088.2500 - val_loss: 236159.6719\n",
      "Epoch 46/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 221981.3594 - val_loss: 232297.4688\n",
      "Epoch 47/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 221687.6719 - val_loss: 232161.4219\n",
      "Epoch 48/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 221647.1094 - val_loss: 231268.0000\n",
      "Epoch 49/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 220629.9219 - val_loss: 231557.0781\n",
      "Epoch 50/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 220205.5156 - val_loss: 231849.5469\n",
      "Epoch 51/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 219377.6562 - val_loss: 232188.4219\n",
      "Epoch 52/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 219601.2812 - val_loss: 231473.0781\n",
      "Epoch 53/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 219397.0938 - val_loss: 231496.0625\n",
      "Epoch 54/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 219404.0625 - val_loss: 231199.3750\n",
      "Epoch 55/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 218912.4062 - val_loss: 230177.9531\n",
      "Epoch 56/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 218877.5000 - val_loss: 239039.1719\n",
      "Epoch 57/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 218985.1719 - val_loss: 231357.6094\n",
      "Epoch 58/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 219054.9219 - val_loss: 231015.3594\n",
      "Epoch 59/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 217828.0156 - val_loss: 231479.7188\n",
      "Epoch 60/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 217603.4844 - val_loss: 230978.9531\n",
      "Epoch 61/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 217023.7969 - val_loss: 229731.1562\n",
      "Epoch 62/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 216869.9062 - val_loss: 230064.9375\n",
      "Epoch 63/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 217911.7812 - val_loss: 227689.8281\n",
      "Epoch 64/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 216777.3750 - val_loss: 228271.6094\n",
      "Epoch 65/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 216587.6875 - val_loss: 226681.8281\n",
      "Epoch 66/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 216131.5000 - val_loss: 228643.1250\n",
      "Epoch 67/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 216825.2812 - val_loss: 227231.4844\n",
      "Epoch 68/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 216503.3906 - val_loss: 229396.6094\n",
      "Epoch 69/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 216963.3438 - val_loss: 226664.0781\n",
      "Epoch 70/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 215401.2344 - val_loss: 229867.1719\n",
      "Epoch 71/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 215114.6406 - val_loss: 226553.5469\n",
      "Epoch 72/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 215824.8281 - val_loss: 227058.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 214693.3281 - val_loss: 226274.2344\n",
      "Epoch 74/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 215105.3125 - val_loss: 225736.8594\n",
      "Epoch 75/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 215031.1250 - val_loss: 226954.4062\n",
      "Epoch 76/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 213750.6719 - val_loss: 227491.5312\n",
      "Epoch 77/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 214736.8906 - val_loss: 227047.6406\n",
      "Epoch 78/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 215044.6094 - val_loss: 224811.8125\n",
      "Epoch 79/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 213986.3750 - val_loss: 225258.1562\n",
      "Epoch 80/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 213750.9375 - val_loss: 226822.6250\n",
      "Epoch 81/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 213876.0625 - val_loss: 224410.4531\n",
      "Epoch 82/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 213760.7969 - val_loss: 225081.5312\n",
      "Epoch 83/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 214197.2344 - val_loss: 224300.0156\n",
      "Epoch 84/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 212739.0938 - val_loss: 224877.0469\n",
      "Epoch 85/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 213935.7812 - val_loss: 225211.7969\n",
      "Epoch 86/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 214030.0156 - val_loss: 224662.2500\n",
      "Epoch 87/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 212758.7969 - val_loss: 225509.8281\n",
      "Epoch 88/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 213279.8906 - val_loss: 223826.6250\n",
      "Epoch 89/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 212716.4062 - val_loss: 223045.9688\n",
      "Epoch 90/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 212630.4688 - val_loss: 230099.1719\n",
      "Epoch 91/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 211928.1875 - val_loss: 225302.7812\n",
      "Epoch 92/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 213078.3125 - val_loss: 227382.4688\n",
      "Epoch 93/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 212435.6875 - val_loss: 225597.1562\n",
      "Epoch 94/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 211847.8125 - val_loss: 222441.0938\n",
      "Epoch 95/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 211618.2031 - val_loss: 226069.7344\n",
      "Epoch 96/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 211941.4844 - val_loss: 222725.9844\n",
      "Epoch 97/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 211367.1250 - val_loss: 225619.1719\n",
      "Epoch 98/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 211708.1406 - val_loss: 222588.5469\n",
      "Epoch 99/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 211199.9375 - val_loss: 222782.9219\n",
      "Epoch 100/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 211695.0625 - val_loss: 223006.7188\n",
      "Epoch 101/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 211377.2969 - val_loss: 222207.6719\n",
      "Epoch 102/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 211044.0312 - val_loss: 223776.2031\n",
      "Epoch 103/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 210867.2812 - val_loss: 223360.2969\n",
      "Epoch 104/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 211145.0938 - val_loss: 222162.4219\n",
      "Epoch 105/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 211054.2500 - val_loss: 223019.9688\n",
      "Epoch 106/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 211436.3125 - val_loss: 222008.8906\n",
      "Epoch 107/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 210606.4219 - val_loss: 221337.9844\n",
      "Epoch 108/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 210706.1406 - val_loss: 221402.6250\n",
      "Epoch 109/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 210591.1250 - val_loss: 222133.6250\n",
      "Epoch 110/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 210237.4688 - val_loss: 224239.2812\n",
      "Epoch 111/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 211976.2812 - val_loss: 221893.0938\n",
      "Epoch 112/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 210135.5781 - val_loss: 223369.0938\n",
      "Epoch 113/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 210126.3750 - val_loss: 220461.7031\n",
      "Epoch 114/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 210947.0938 - val_loss: 221402.7344\n",
      "Epoch 115/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 210999.6094 - val_loss: 222613.3281\n",
      "Epoch 116/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 210266.7031 - val_loss: 220854.5781\n",
      "Epoch 117/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 210004.8594 - val_loss: 220320.6094\n",
      "Epoch 118/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 210156.8438 - val_loss: 222039.5312\n",
      "Epoch 119/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 209838.0625 - val_loss: 220542.5781\n",
      "Epoch 120/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 209777.5000 - val_loss: 222229.1875\n",
      "Epoch 121/500\n",
      "219/219 [==============================] - 0s 633us/step - loss: 210309.7656 - val_loss: 222857.2031\n",
      "Epoch 122/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 209649.4844 - val_loss: 222203.6094\n",
      "Epoch 123/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 209135.0469 - val_loss: 221323.4844\n",
      "Epoch 124/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 209344.7812 - val_loss: 223821.2812\n",
      "Epoch 125/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 209359.8750 - val_loss: 220675.6875\n",
      "Epoch 126/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 209457.5000 - val_loss: 225000.8594\n",
      "Epoch 127/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 208810.9062 - val_loss: 223814.3906\n",
      "Epoch 128/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 209226.4062 - val_loss: 220037.5000\n",
      "Epoch 129/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 209119.6875 - val_loss: 224440.4531\n",
      "Epoch 130/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 209093.0625 - val_loss: 224332.0156\n",
      "Epoch 131/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 208651.9375 - val_loss: 218950.5156\n",
      "Epoch 132/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 209285.7031 - val_loss: 223438.1719\n",
      "Epoch 133/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 208732.1875 - val_loss: 219695.2500\n",
      "Epoch 134/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 209183.3281 - val_loss: 220927.5469\n",
      "Epoch 135/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 208205.0938 - val_loss: 221208.0312\n",
      "Epoch 136/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 208473.2656 - val_loss: 224092.3125\n",
      "Epoch 137/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 208909.6094 - val_loss: 219994.7656\n",
      "Epoch 138/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 208941.2969 - val_loss: 220232.3281\n",
      "Epoch 139/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 208239.1562 - val_loss: 220767.8281\n",
      "Epoch 140/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 208990.4688 - val_loss: 222379.8594\n",
      "Epoch 141/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 208351.2188 - val_loss: 219698.7031\n",
      "Epoch 142/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 209049.5000 - val_loss: 218777.3125\n",
      "Epoch 143/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 208185.3594 - val_loss: 220974.2031\n",
      "Epoch 144/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 638us/step - loss: 207881.4688 - val_loss: 220243.2500\n",
      "Epoch 145/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 209165.6562 - val_loss: 221627.8125\n",
      "Epoch 146/500\n",
      "219/219 [==============================] - 0s 633us/step - loss: 209121.2188 - val_loss: 221499.0625\n",
      "Epoch 147/500\n",
      "219/219 [==============================] - 0s 633us/step - loss: 208406.8906 - val_loss: 218480.1875\n",
      "Epoch 148/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 208137.0156 - val_loss: 220748.9062\n",
      "Epoch 149/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 207720.4531 - val_loss: 222733.5781\n",
      "Epoch 150/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 207452.0000 - val_loss: 221726.6875\n",
      "Epoch 151/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 208521.9062 - val_loss: 220166.2812\n",
      "Epoch 152/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 208100.1875 - val_loss: 219425.0938\n",
      "Epoch 153/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 208589.6250 - val_loss: 224392.1719\n",
      "Epoch 154/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 208605.2969 - val_loss: 219279.3125\n",
      "Epoch 155/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 208205.9688 - val_loss: 221759.7812\n",
      "Epoch 156/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 208132.6562 - val_loss: 219756.3125\n",
      "Epoch 157/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 207342.6250 - val_loss: 220931.7812\n",
      "Epoch 158/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 208412.6719 - val_loss: 221253.9375\n",
      "Epoch 159/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 207773.3281 - val_loss: 220319.2031\n",
      "Epoch 160/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 206731.8125 - val_loss: 220983.3281\n",
      "Epoch 161/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 207354.4844 - val_loss: 223033.5469\n",
      "Epoch 162/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 207679.0312 - val_loss: 220492.9844\n",
      "Epoch 163/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 207754.6406 - val_loss: 218668.3906\n",
      "Epoch 164/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 207881.0156 - val_loss: 222874.9531\n",
      "Epoch 165/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 207567.1094 - val_loss: 220113.0156\n",
      "Epoch 166/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 207173.0625 - val_loss: 220334.6719\n",
      "Epoch 167/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 207141.7188 - val_loss: 218897.2188\n",
      "Epoch 168/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 206304.8281 - val_loss: 219125.1094\n",
      "Epoch 169/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 206830.4219 - val_loss: 218676.9062\n",
      "Epoch 170/500\n",
      "219/219 [==============================] - 0s 633us/step - loss: 207742.0469 - val_loss: 218147.5000\n",
      "Epoch 171/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 207356.5625 - val_loss: 218751.6875\n",
      "Epoch 172/500\n",
      "219/219 [==============================] - 0s 633us/step - loss: 206611.0312 - val_loss: 218147.8125\n",
      "Epoch 173/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 206348.3281 - val_loss: 218189.0625\n",
      "Epoch 174/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 207311.7500 - val_loss: 219318.3750\n",
      "Epoch 175/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 207318.9375 - val_loss: 220338.5781\n",
      "Epoch 176/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 206321.2969 - val_loss: 217745.6406\n",
      "Epoch 177/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 206890.9531 - val_loss: 220573.1719\n",
      "Epoch 178/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 206784.6094 - val_loss: 217822.9219\n",
      "Epoch 179/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 206345.4844 - val_loss: 219496.6719\n",
      "Epoch 180/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 206242.4531 - val_loss: 217934.4062\n",
      "Epoch 181/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 206740.6875 - val_loss: 218735.2812\n",
      "Epoch 182/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 206530.5781 - val_loss: 219050.6719\n",
      "Epoch 183/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 206544.9688 - val_loss: 217627.1562\n",
      "Epoch 184/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 206086.9844 - val_loss: 221041.3906\n",
      "Epoch 185/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 206344.5156 - val_loss: 218682.2969\n",
      "Epoch 186/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 206169.0469 - val_loss: 219503.1719\n",
      "Epoch 187/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 205910.8281 - val_loss: 218114.5156\n",
      "Epoch 188/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 205788.9688 - val_loss: 217734.0938\n",
      "Epoch 189/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 206524.7812 - val_loss: 221453.5312\n",
      "Epoch 190/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 206347.5938 - val_loss: 219507.5000\n",
      "Epoch 191/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 206661.3125 - val_loss: 219089.9531\n",
      "Epoch 192/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 206596.5781 - val_loss: 220043.8750\n",
      "Epoch 193/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 205754.0469 - val_loss: 222646.4219\n",
      "Epoch 194/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 206738.7344 - val_loss: 216904.2344\n",
      "Epoch 195/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 205544.6562 - val_loss: 216900.3438\n",
      "Epoch 196/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 205863.3750 - val_loss: 216850.3750\n",
      "Epoch 197/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 205601.1719 - val_loss: 219183.7969\n",
      "Epoch 198/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 205104.1719 - val_loss: 218552.9375\n",
      "Epoch 199/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 205630.4219 - val_loss: 218195.0312\n",
      "Epoch 200/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 205378.5156 - val_loss: 219235.7812\n",
      "Epoch 201/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 206393.8750 - val_loss: 222894.8750\n",
      "Epoch 202/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 205658.5625 - val_loss: 218325.5312\n",
      "Epoch 203/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 205704.8438 - val_loss: 217302.9219\n",
      "Epoch 204/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 205327.2188 - val_loss: 218485.9688\n",
      "Epoch 205/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 204879.9375 - val_loss: 217475.1719\n",
      "Epoch 206/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 205096.9062 - val_loss: 219645.9062\n",
      "Epoch 207/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 204511.9062 - val_loss: 218410.9375\n",
      "Epoch 208/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 204497.1094 - val_loss: 219795.5781\n",
      "Epoch 209/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 205750.0781 - val_loss: 219415.2344\n",
      "Epoch 210/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 205406.5000 - val_loss: 217185.9219\n",
      "Epoch 211/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 205317.9844 - val_loss: 224767.4531\n",
      "Epoch 212/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 205179.0469 - val_loss: 216305.7969\n",
      "Epoch 213/500\n",
      "219/219 [==============================] - 0s 633us/step - loss: 205019.7500 - val_loss: 216536.5625\n",
      "Epoch 214/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 204706.2656 - val_loss: 216220.2188\n",
      "Epoch 215/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 638us/step - loss: 204633.2812 - val_loss: 217391.9062\n",
      "Epoch 216/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 204455.0156 - val_loss: 218814.9531\n",
      "Epoch 217/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 204709.3594 - val_loss: 216775.7188\n",
      "Epoch 218/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 204304.3438 - val_loss: 216473.0625\n",
      "Epoch 219/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 204096.7344 - val_loss: 217420.8906\n",
      "Epoch 220/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 205061.0469 - val_loss: 215619.7812\n",
      "Epoch 221/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 204791.5000 - val_loss: 218566.7656\n",
      "Epoch 222/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 203974.1406 - val_loss: 217252.3125\n",
      "Epoch 223/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 204866.5312 - val_loss: 216223.3594\n",
      "Epoch 224/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 204422.0312 - val_loss: 217597.9375\n",
      "Epoch 225/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 204279.0625 - val_loss: 217183.4688\n",
      "Epoch 226/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 204362.7031 - val_loss: 217761.6406\n",
      "Epoch 227/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 204296.2344 - val_loss: 216493.9219\n",
      "Epoch 228/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 203359.2344 - val_loss: 215828.9531\n",
      "Epoch 229/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 203805.0938 - val_loss: 217911.8125\n",
      "Epoch 230/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 203859.2344 - val_loss: 218281.5156\n",
      "Epoch 231/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 204035.4375 - val_loss: 216126.3594\n",
      "Epoch 232/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 203857.5312 - val_loss: 215450.1719\n",
      "Epoch 233/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 203533.3906 - val_loss: 217377.6094\n",
      "Epoch 234/500\n",
      "219/219 [==============================] - 0s 674us/step - loss: 204922.0781 - val_loss: 219247.1406\n",
      "Epoch 235/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 204332.0938 - val_loss: 217229.9375\n",
      "Epoch 236/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 203211.9219 - val_loss: 216739.4531\n",
      "Epoch 237/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 204484.6875 - val_loss: 215993.0469\n",
      "Epoch 238/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 203541.7031 - val_loss: 217970.5312\n",
      "Epoch 239/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 203217.4375 - val_loss: 218742.5938\n",
      "Epoch 240/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 203547.3281 - val_loss: 222495.5781\n",
      "Epoch 241/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 203829.7188 - val_loss: 216808.6562\n",
      "Epoch 242/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 204106.6094 - val_loss: 218586.6406\n",
      "Epoch 243/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 203808.5469 - val_loss: 215745.3281\n",
      "Epoch 244/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 203661.3281 - val_loss: 219326.3594\n",
      "Epoch 245/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 203574.3125 - val_loss: 217159.6406\n",
      "Epoch 246/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 203597.7500 - val_loss: 215696.6719\n",
      "Epoch 247/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 203715.4688 - val_loss: 217611.4219\n",
      "Epoch 248/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 203601.9375 - val_loss: 217298.3906\n",
      "Epoch 249/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 202389.2656 - val_loss: 214413.4688\n",
      "Epoch 250/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 202580.8594 - val_loss: 216227.8594\n",
      "Epoch 251/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 202793.5000 - val_loss: 219779.6875\n",
      "Epoch 252/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 204464.6250 - val_loss: 216641.6875\n",
      "Epoch 253/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 202659.5625 - val_loss: 215821.9375\n",
      "Epoch 254/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 202837.5781 - val_loss: 216797.3594\n",
      "Epoch 255/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 202286.4062 - val_loss: 214497.6562\n",
      "Epoch 256/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 203470.0781 - val_loss: 216672.0312\n",
      "Epoch 257/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 203485.6562 - val_loss: 215924.4688\n",
      "Epoch 258/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 203831.1250 - val_loss: 215207.7031\n",
      "Epoch 259/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 202628.0156 - val_loss: 215842.3594\n",
      "Epoch 260/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 202259.8750 - val_loss: 223244.6250\n",
      "Epoch 261/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 203285.8594 - val_loss: 223558.4062\n",
      "Epoch 262/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 203019.4375 - val_loss: 214450.0625\n",
      "Epoch 263/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 202242.8438 - val_loss: 215058.0625\n",
      "Epoch 264/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 202603.7812 - val_loss: 215464.3281\n",
      "Epoch 265/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 201573.5156 - val_loss: 216648.4375\n",
      "Epoch 266/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 202148.1875 - val_loss: 217383.4688\n",
      "Epoch 267/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 202145.6406 - val_loss: 216439.8125\n",
      "Epoch 268/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 201883.8125 - val_loss: 217112.0938\n",
      "Epoch 269/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 202231.2031 - val_loss: 214406.8906\n",
      "Epoch 270/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 201930.9531 - val_loss: 214614.3125\n",
      "Epoch 271/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 201840.6094 - val_loss: 215060.0938\n",
      "Epoch 272/500\n",
      "219/219 [==============================] - 0s 674us/step - loss: 202282.3125 - val_loss: 214315.4531\n",
      "Epoch 273/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 202103.1406 - val_loss: 216702.4219\n",
      "Epoch 274/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 202548.0000 - val_loss: 215833.9531\n",
      "Epoch 275/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 202076.7344 - val_loss: 215674.5938\n",
      "Epoch 276/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 202072.8594 - val_loss: 216514.8438\n",
      "Epoch 277/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 200863.5625 - val_loss: 221662.5156\n",
      "Epoch 278/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 202716.5625 - val_loss: 214752.8281\n",
      "Epoch 279/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 201280.5312 - val_loss: 217199.8594\n",
      "Epoch 280/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 201366.1562 - val_loss: 220235.2656\n",
      "Epoch 281/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 202621.3906 - val_loss: 215364.6875\n",
      "Epoch 282/500\n",
      "219/219 [==============================] - 0s 665us/step - loss: 201025.5312 - val_loss: 217114.3750\n",
      "Epoch 283/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 201906.5312 - val_loss: 213907.3125\n",
      "Epoch 284/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 201659.4844 - val_loss: 218172.4062\n",
      "Epoch 285/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 200914.0938 - val_loss: 213509.2969\n",
      "Epoch 286/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 642us/step - loss: 200717.0469 - val_loss: 214665.7969\n",
      "Epoch 287/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 200824.2344 - val_loss: 217524.3906\n",
      "Epoch 288/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 200649.6250 - val_loss: 214436.7344\n",
      "Epoch 289/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 200369.9375 - val_loss: 217349.5469\n",
      "Epoch 290/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 200834.3438 - val_loss: 214826.2344\n",
      "Epoch 291/500\n",
      "219/219 [==============================] - 0s 679us/step - loss: 200800.1094 - val_loss: 212439.7812\n",
      "Epoch 292/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 200802.3906 - val_loss: 215950.5938\n",
      "Epoch 293/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 201012.6094 - val_loss: 219576.8750\n",
      "Epoch 294/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 200415.7969 - val_loss: 217396.7656\n",
      "Epoch 295/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 200731.7031 - val_loss: 214724.7656\n",
      "Epoch 296/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 201078.3125 - val_loss: 219043.2344\n",
      "Epoch 297/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 200633.6875 - val_loss: 212578.6094\n",
      "Epoch 298/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 202491.6562 - val_loss: 215852.7812\n",
      "Epoch 299/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 200922.1406 - val_loss: 214581.1094\n",
      "Epoch 300/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 200133.8750 - val_loss: 215152.0781\n",
      "Epoch 301/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 199748.8594 - val_loss: 214306.5625\n",
      "Epoch 302/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 200265.8594 - val_loss: 216383.9688\n",
      "Epoch 303/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 201020.7969 - val_loss: 211814.5938\n",
      "Epoch 304/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 199903.9688 - val_loss: 213933.7500\n",
      "Epoch 305/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 199469.8750 - val_loss: 219777.3281\n",
      "Epoch 306/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 200693.1719 - val_loss: 214215.8281\n",
      "Epoch 307/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 199875.3750 - val_loss: 214779.4375\n",
      "Epoch 308/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 200308.0938 - val_loss: 212701.6406\n",
      "Epoch 309/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 199712.3125 - val_loss: 212208.7656\n",
      "Epoch 310/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 199458.0625 - val_loss: 215695.7812\n",
      "Epoch 311/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 198961.9844 - val_loss: 213157.9219\n",
      "Epoch 312/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 199419.3438 - val_loss: 213530.2969\n",
      "Epoch 313/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 200471.5781 - val_loss: 220393.8750\n",
      "Epoch 314/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 199943.8594 - val_loss: 212701.6250\n",
      "Epoch 315/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 199680.0156 - val_loss: 212186.0781\n",
      "Epoch 316/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 198912.5156 - val_loss: 212812.0781\n",
      "Epoch 317/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 199336.5781 - val_loss: 211468.7656\n",
      "Epoch 318/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 200786.5781 - val_loss: 227877.4219\n",
      "Epoch 319/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 199845.6562 - val_loss: 210795.0625\n",
      "Epoch 320/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 200096.8594 - val_loss: 212694.3906\n",
      "Epoch 321/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 198727.7656 - val_loss: 212006.9375\n",
      "Epoch 322/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 199345.9219 - val_loss: 224434.3125\n",
      "Epoch 323/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 199678.9375 - val_loss: 211719.4844\n",
      "Epoch 324/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 199667.7031 - val_loss: 212466.4062\n",
      "Epoch 325/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 199544.0312 - val_loss: 214786.7188\n",
      "Epoch 326/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 200367.9844 - val_loss: 214994.6719\n",
      "Epoch 327/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 199478.5156 - val_loss: 211420.6250\n",
      "Epoch 328/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 199143.7500 - val_loss: 212625.1875\n",
      "Epoch 329/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 198976.8906 - val_loss: 212333.5469\n",
      "Epoch 330/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 199537.1875 - val_loss: 218549.1719\n",
      "Epoch 331/500\n",
      "219/219 [==============================] - 0s 670us/step - loss: 200460.4375 - val_loss: 214158.6250\n",
      "Epoch 332/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198126.2344 - val_loss: 211468.8438\n",
      "Epoch 333/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 199640.2188 - val_loss: 212931.7969\n",
      "Epoch 334/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198602.5156 - val_loss: 212392.4688\n",
      "Epoch 335/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198653.6562 - val_loss: 210559.2031\n",
      "Epoch 336/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198313.0625 - val_loss: 212927.8281\n",
      "Epoch 337/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 199417.9219 - val_loss: 213376.0000\n",
      "Epoch 338/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198336.6719 - val_loss: 220865.8750\n",
      "Epoch 339/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 198972.5000 - val_loss: 213225.7188\n",
      "Epoch 340/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198140.6094 - val_loss: 212961.1719\n",
      "Epoch 341/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198460.1094 - val_loss: 216907.5938\n",
      "Epoch 342/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 199294.0781 - val_loss: 212370.7656\n",
      "Epoch 343/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 199313.3594 - val_loss: 213781.5312\n",
      "Epoch 344/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198533.9062 - val_loss: 213165.7969\n",
      "Epoch 345/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 198041.7031 - val_loss: 210409.8125\n",
      "Epoch 346/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 198694.8750 - val_loss: 212600.0312\n",
      "Epoch 347/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 199568.5312 - val_loss: 213838.3906\n",
      "Epoch 348/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198721.2031 - val_loss: 214984.7812\n",
      "Epoch 349/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 198163.9844 - val_loss: 210644.8906\n",
      "Epoch 350/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 198783.2344 - val_loss: 211529.0938\n",
      "Epoch 351/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 197973.7344 - val_loss: 212489.7500\n",
      "Epoch 352/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198714.2812 - val_loss: 211612.5000\n",
      "Epoch 353/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 197346.7188 - val_loss: 214213.4062\n",
      "Epoch 354/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198528.2344 - val_loss: 214948.5156\n",
      "Epoch 355/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 197663.5312 - val_loss: 215157.2969\n",
      "Epoch 356/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 197318.6406 - val_loss: 212549.5469\n",
      "Epoch 357/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 642us/step - loss: 197616.4062 - val_loss: 215996.8906\n",
      "Epoch 358/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198126.1719 - val_loss: 210223.4844\n",
      "Epoch 359/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 198516.7344 - val_loss: 213963.5312\n",
      "Epoch 360/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 197526.9219 - val_loss: 211400.1875\n",
      "Epoch 361/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 197840.7188 - val_loss: 212725.6094\n",
      "Epoch 362/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 197513.2188 - val_loss: 209765.5469\n",
      "Epoch 363/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 198425.6094 - val_loss: 215480.0938\n",
      "Epoch 364/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196994.0156 - val_loss: 212339.5938\n",
      "Epoch 365/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196821.8438 - val_loss: 217896.0312\n",
      "Epoch 366/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 197509.8594 - val_loss: 212096.2969\n",
      "Epoch 367/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 197736.6250 - val_loss: 214066.6719\n",
      "Epoch 368/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 196429.7969 - val_loss: 212762.7188\n",
      "Epoch 369/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 197295.8125 - val_loss: 210995.5469\n",
      "Epoch 370/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 197682.9219 - val_loss: 210770.2812\n",
      "Epoch 371/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196590.9375 - val_loss: 212188.6250\n",
      "Epoch 372/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 197853.5156 - val_loss: 214657.7344\n",
      "Epoch 373/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 198451.8594 - val_loss: 214533.7500\n",
      "Epoch 374/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 196888.8594 - val_loss: 217348.6562\n",
      "Epoch 375/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 196192.7812 - val_loss: 215405.0156\n",
      "Epoch 376/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 197521.3906 - val_loss: 212378.9531\n",
      "Epoch 377/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 197593.0000 - val_loss: 210799.3750\n",
      "Epoch 378/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 197687.5781 - val_loss: 214737.6562\n",
      "Epoch 379/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 198475.1562 - val_loss: 214984.6875\n",
      "Epoch 380/500\n",
      "219/219 [==============================] - 0s 674us/step - loss: 196092.0156 - val_loss: 211235.5625\n",
      "Epoch 381/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 196901.6875 - val_loss: 216034.7344\n",
      "Epoch 382/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 196700.4375 - val_loss: 219225.0156\n",
      "Epoch 383/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 197432.1719 - val_loss: 211743.3281\n",
      "Epoch 384/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 195809.1562 - val_loss: 227247.3125\n",
      "Epoch 385/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 197107.9375 - val_loss: 210435.1250\n",
      "Epoch 386/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 197868.7969 - val_loss: 215703.1406\n",
      "Epoch 387/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 197110.0312 - val_loss: 216647.5625\n",
      "Epoch 388/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196997.5312 - val_loss: 219636.2031\n",
      "Epoch 389/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 197366.1562 - val_loss: 220687.7188\n",
      "Epoch 390/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 197090.7969 - val_loss: 212605.0781\n",
      "Epoch 391/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 197709.7500 - val_loss: 213800.7188\n",
      "Epoch 392/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 197508.7500 - val_loss: 211053.8594\n",
      "Epoch 393/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 196169.1250 - val_loss: 221221.4375\n",
      "Epoch 394/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 196372.6562 - val_loss: 211150.0625\n",
      "Epoch 395/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 196220.6719 - val_loss: 216498.4219\n",
      "Epoch 396/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 197193.4688 - val_loss: 214907.5469\n",
      "Epoch 397/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 195773.4062 - val_loss: 209170.7812\n",
      "Epoch 398/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 196898.3750 - val_loss: 209370.8750\n",
      "Epoch 399/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196418.1875 - val_loss: 211592.1250\n",
      "Epoch 400/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 195888.9531 - val_loss: 211215.1406\n",
      "Epoch 401/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 197092.2031 - val_loss: 221350.7969\n",
      "Epoch 402/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 197143.3594 - val_loss: 211030.8125\n",
      "Epoch 403/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196582.3594 - val_loss: 220828.3906\n",
      "Epoch 404/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 196212.6406 - val_loss: 210951.7812\n",
      "Epoch 405/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 196299.3906 - val_loss: 213799.4844\n",
      "Epoch 406/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 195917.4844 - val_loss: 210841.6094\n",
      "Epoch 407/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 195904.7656 - val_loss: 211574.0469\n",
      "Epoch 408/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 196210.8750 - val_loss: 211432.8750\n",
      "Epoch 409/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 196070.9844 - val_loss: 214759.5000\n",
      "Epoch 410/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196175.6875 - val_loss: 209812.3438\n",
      "Epoch 411/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196060.2969 - val_loss: 211760.9688\n",
      "Epoch 412/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 195745.5312 - val_loss: 212033.6562\n",
      "Epoch 413/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 196432.8906 - val_loss: 215062.0781\n",
      "Epoch 414/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196700.3125 - val_loss: 217214.1875\n",
      "Epoch 415/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 195449.4688 - val_loss: 209940.6875\n",
      "Epoch 416/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 194572.7656 - val_loss: 209301.2031\n",
      "Epoch 417/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196013.4219 - val_loss: 212389.8438\n",
      "Epoch 418/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196315.4375 - val_loss: 213599.7969\n",
      "Epoch 419/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 195765.8125 - val_loss: 214437.7656\n",
      "Epoch 420/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 195385.1250 - val_loss: 210424.5469\n",
      "Epoch 421/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 196154.7656 - val_loss: 212212.2812\n",
      "Epoch 422/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 195492.0938 - val_loss: 209379.1250\n",
      "Epoch 423/500\n",
      "219/219 [==============================] - 0s 674us/step - loss: 195014.3594 - val_loss: 211410.0312\n",
      "Epoch 424/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196514.9531 - val_loss: 211413.5938\n",
      "Epoch 425/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 195715.2344 - val_loss: 216687.2812\n",
      "Epoch 426/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 195869.4219 - val_loss: 208766.5312\n",
      "Epoch 427/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 195084.7500 - val_loss: 208623.5469\n",
      "Epoch 428/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 642us/step - loss: 196213.9531 - val_loss: 209209.0781\n",
      "Epoch 429/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 194806.4844 - val_loss: 209208.2031\n",
      "Epoch 430/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 195118.1406 - val_loss: 214333.9219\n",
      "Epoch 431/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 196266.0156 - val_loss: 216006.7031\n",
      "Epoch 432/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 196013.5000 - val_loss: 210491.7188\n",
      "Epoch 433/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 195321.5469 - val_loss: 210605.4219\n",
      "Epoch 434/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 195780.0625 - val_loss: 210565.2656\n",
      "Epoch 435/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 195246.3906 - val_loss: 211868.0781\n",
      "Epoch 436/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 195995.0625 - val_loss: 211714.9219\n",
      "Epoch 437/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 194098.4062 - val_loss: 210544.7188\n",
      "Epoch 438/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 194427.3281 - val_loss: 210138.8125\n",
      "Epoch 439/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 195132.6094 - val_loss: 212167.2344\n",
      "Epoch 440/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 195593.0469 - val_loss: 209612.0625\n",
      "Epoch 441/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 194870.9219 - val_loss: 210277.2188\n",
      "Epoch 442/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 195272.5156 - val_loss: 210251.6719\n",
      "Epoch 443/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 195693.7656 - val_loss: 209176.7188\n",
      "Epoch 444/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 195402.2500 - val_loss: 211296.5781\n",
      "Epoch 445/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 194489.7969 - val_loss: 208159.3750\n",
      "Epoch 446/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 194434.5938 - val_loss: 211318.6875\n",
      "Epoch 447/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 195428.8594 - val_loss: 208518.3594\n",
      "Epoch 448/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 194893.6094 - val_loss: 213246.8906\n",
      "Epoch 449/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 195107.4531 - val_loss: 209536.6406\n",
      "Epoch 450/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 193708.3438 - val_loss: 213354.2812\n",
      "Epoch 451/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 193951.9844 - val_loss: 215616.2344\n",
      "Epoch 452/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 193848.2188 - val_loss: 216605.8594\n",
      "Epoch 453/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 194557.2031 - val_loss: 212618.5781\n",
      "Epoch 454/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 194470.0469 - val_loss: 210426.3906\n",
      "Epoch 455/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 194923.9844 - val_loss: 208944.2188\n",
      "Epoch 456/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 194275.0938 - val_loss: 207445.9375\n",
      "Epoch 457/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 194383.7500 - val_loss: 214801.4062\n",
      "Epoch 458/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 194512.5469 - val_loss: 208182.0156\n",
      "Epoch 459/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 194671.7656 - val_loss: 212980.4531\n",
      "Epoch 460/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 194448.8906 - val_loss: 208236.4062\n",
      "Epoch 461/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 193996.8594 - val_loss: 215383.5469\n",
      "Epoch 462/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 194670.6875 - val_loss: 211552.3125\n",
      "Epoch 463/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 194451.3906 - val_loss: 209739.5938\n",
      "Epoch 464/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 194685.6250 - val_loss: 211663.9375\n",
      "Epoch 465/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 194056.9688 - val_loss: 209395.6094\n",
      "Epoch 466/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 194462.7344 - val_loss: 209435.7500\n",
      "Epoch 467/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 193734.2344 - val_loss: 220645.7969\n",
      "Epoch 468/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 194429.8750 - val_loss: 208130.8906\n",
      "Epoch 469/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 193437.0000 - val_loss: 214685.6875\n",
      "Epoch 470/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 194214.8281 - val_loss: 209884.2344\n",
      "Epoch 471/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 193339.8906 - val_loss: 207654.8281\n",
      "Epoch 472/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 193817.2812 - val_loss: 214119.2344\n",
      "Epoch 473/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 194740.7812 - val_loss: 208877.6250\n",
      "Epoch 474/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 194314.0469 - val_loss: 208638.9531\n",
      "Epoch 475/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 194610.3906 - val_loss: 212006.1250\n",
      "Epoch 476/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 193445.8594 - val_loss: 209995.5781\n",
      "Epoch 477/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 194369.7188 - val_loss: 209489.7969\n",
      "Epoch 478/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 194842.6406 - val_loss: 207662.3594\n",
      "Epoch 479/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 195017.8594 - val_loss: 210462.5938\n",
      "Epoch 480/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 192997.9219 - val_loss: 212265.1562\n",
      "Epoch 481/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 194801.2344 - val_loss: 208714.5156\n",
      "Epoch 482/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 193420.9062 - val_loss: 209845.2344\n",
      "Epoch 483/500\n",
      "219/219 [==============================] - 0s 656us/step - loss: 194016.3281 - val_loss: 211104.0312\n",
      "Epoch 484/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 192331.2500 - val_loss: 209025.1250\n",
      "Epoch 485/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 193834.7656 - val_loss: 208499.4531\n",
      "Epoch 486/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 193862.1250 - val_loss: 211196.1094\n",
      "Epoch 487/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 194104.8750 - val_loss: 209328.2969\n",
      "Epoch 488/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 194009.9844 - val_loss: 209690.7812\n",
      "Epoch 489/500\n",
      "219/219 [==============================] - 0s 661us/step - loss: 193315.8906 - val_loss: 207422.2031\n",
      "Epoch 490/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 193762.5781 - val_loss: 216865.7969\n",
      "Epoch 491/500\n",
      "219/219 [==============================] - 0s 652us/step - loss: 193059.9219 - val_loss: 215931.2188\n",
      "Epoch 492/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 194332.1719 - val_loss: 211482.0781\n",
      "Epoch 493/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 193363.8594 - val_loss: 212444.7500\n",
      "Epoch 494/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 193617.9062 - val_loss: 209354.9062\n",
      "Epoch 495/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 193171.6875 - val_loss: 219973.0781\n",
      "Epoch 496/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 193815.4219 - val_loss: 210846.3438\n",
      "Epoch 497/500\n",
      "219/219 [==============================] - 0s 638us/step - loss: 194098.7188 - val_loss: 211484.4219\n",
      "Epoch 498/500\n",
      "219/219 [==============================] - 0s 647us/step - loss: 194267.1562 - val_loss: 207602.4844\n",
      "Epoch 499/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 647us/step - loss: 194099.9062 - val_loss: 211010.9219\n",
      "Epoch 500/500\n",
      "219/219 [==============================] - 0s 642us/step - loss: 193576.5781 - val_loss: 209486.6719\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=500, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d082ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b634b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2bef96dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.499461551783577 209486.64696846405\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4de7d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3707700744402883 263346.93717819237\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(r2_score(y_test, y_pred), mean_squared_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
